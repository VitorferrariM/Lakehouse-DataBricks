üåå Projeto: Pipeline de Dados ‚Äî NASA API com Databricks Lakehouse

Este projeto tem como objetivo construir um pipeline de engenharia de dados completo, desde a ingest√£o at√© a visualiza√ß√£o, utilizando a arquitetura Lakehouse no Databricks.
Os dados s√£o coletados da API p√∫blica da NASA, armazenados em camadas no Amazon S3 e processados no Databricks, com suporte adicional de DuckDB para consultas locais e Streamlit para visualiza√ß√£o.

‚öôÔ∏è Arquitetura e Fluxo de Dados
O fluxo segue o modelo Medalh√£o (Bronze ‚Üí Silver ‚Üí Gold):

Ingest√£o
Linguagem: Python
Ferramentas: Databricks Notebooks
Fonte de dados: NASA API
Armazenamento inicial: Amazon S3 (Bronze)
Arquivos salvos em formato JSON e convertidos para Parquet

Armazenamento e Load
Amazon S3 para camadas Bronze/Silver/Gold
DuckDB para testes e consultas locais
Controle de permiss√µes via AWS IAM

Transforma√ß√£o
Databricks SQL e PySpark
Limpeza, tratamento e normaliza√ß√£o dos dados (Silver)
Cria√ß√£o de m√©tricas e agrega√ß√µes (Gold)

Visualiza√ß√£o
Streamlit conectado √† camada Gold





Dashboards interativos mostrando os principais insights dos dados da NASA

