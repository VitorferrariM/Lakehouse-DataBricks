{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba5f0c0-da2e-4d71-92b8-d60c112c6686",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "# Requisição à API da NASA\n",
    "url = (\n",
    "    \"https://api.nasa.gov/insight_weather/\"\n",
    "    \"?api_key=ywTPslt9SJHevhcwYCBGOCLTVjG1K6FsHRRjJksJ\"\n",
    "    \"&feedtype=json&ver=1.0\"\n",
    ")\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Extrair os dias válidos (sols)\n",
    "sol_keys = data.get(\"sol_keys\", [])\n",
    "records = []\n",
    "\n",
    "for sol in sol_keys:\n",
    "    sol_data = data.get(sol, {})\n",
    "    at = sol_data.get(\"AT\", {}) or {}\n",
    "    pre = sol_data.get(\"PRE\", {}) or {}\n",
    "\n",
    "    record = {\n",
    "        \"sol\": sol,\n",
    "        \"season\": sol_data.get(\"Season\"),\n",
    "        \"first_utc\": sol_data.get(\"First_UTC\"),\n",
    "        \"last_utc\": sol_data.get(\"Last_UTC\"),\n",
    "        \"temp_avg\": at.get(\"av\", None),\n",
    "        \"temp_min\": at.get(\"mn\", None),\n",
    "        \"temp_max\": at.get(\"mx\", None),\n",
    "        \"pressure_avg\": pre.get(\"av\", None),\n",
    "        \"pressure_min\": pre.get(\"mn\", None),\n",
    "        \"pressure_max\": pre.get(\"mx\", None),\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "# Definir schema explícito para evitar erro de inferência\n",
    "schema = StructType([\n",
    "    StructField(\"sol\", StringType(), True),\n",
    "    StructField(\"season\", StringType(), True),\n",
    "    StructField(\"first_utc\", StringType(), True),\n",
    "    StructField(\"last_utc\", StringType(), True),\n",
    "    StructField(\"temp_avg\", DoubleType(), True),\n",
    "    StructField(\"temp_min\", DoubleType(), True),\n",
    "    StructField(\"temp_max\", DoubleType(), True),\n",
    "    StructField(\"pressure_avg\", DoubleType(), True),\n",
    "    StructField(\"pressure_min\", DoubleType(), True),\n",
    "    StructField(\"pressure_max\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Criar DataFrame com schema\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_bronze = spark.createDataFrame(records, schema=schema)\n",
    "\n",
    "# Mostrar estrutura e dados\n",
    "df_bronze.printSchema()\n",
    "display(df_bronze)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
